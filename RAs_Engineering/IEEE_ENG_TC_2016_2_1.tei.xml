<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DwarfCode: A Performance Prediction Tool for Parallel Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Weizhe</forename><surname>Zhang</surname></persName>
							<email>wzzhang@hit.edu.cn.</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Albert</forename><forename type="middle">M K</forename><surname>Cheng</surname></persName>
							<email>cheng@cs.uh.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Jaspal</forename><surname>Subhlok</surname></persName>
							<email>jsubhlok@central.uh.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<postCode>150001</postCode>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Sci-ence</orgName>
								<orgName type="institution">University of Houston</orgName>
								<address>
									<postCode>77204</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DwarfCode: A Performance Prediction Tool for Parallel Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TC.2015.2417526</idno>
					<note type="submission">received 19 Mar. 2014; revised 1 Mar. 2015; accepted 17 Mar. 2015. Date of publication 29 Apr. 2015; date of current version 15 Jan. 2016.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-03-16T04:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Performance prediction</term>
					<term>MPI application</term>
					<term>DwarfCode</term>
					<term>trace merging</term>
					<term>trace compressing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present DwarfCode, a performance prediction tool for MPI applications on diverse computing platforms. The goal is to accurately predict the running time of applications for task scheduling and job migration. First, DwarfCode collects the execution traces to record the computing and communication events. Then, it merges the traces from different processes into a single trace. After that, DwarfCode identifies and compresses the repeating patterns in the final trace to shrink the size of the events. Finally, a dwarf code is generated to mimic the original program behavior. This smaller running benchmark is replayed in the target platform to predict the performance of the original application. In order to generate such a benchmark, two major challenges are to reduce the time complexity of trace merging and repeat compression algorithms. We propose an O(mpn) trace merging algorithm to combine the traces generated by separate MPI processes, where m denotes the upper bound of tracing distance, p denotes the number of processes, and n denotes the maximum of event numbers of all the traces. More importantly, we put forward a novel repeat compression algorithm, whose time complexity is O(nlogn). Experimental results show that DwarfCode can accurately predict the running time of MPI applications. The error rate is below 10 percent for compute and communication intensive applications. This toolkit has been released for free download as a GNU General Public License v3 software.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>P ERFORMANCE prediction of applications is a prerequisite for resource management in various computing platforms, such as task scheduling and job migration <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Traditional performance prediction approaches fall into two branches: trace-driven and model-driven. The trace-driven prediction generates the execution logs of applications. When an identical application is rescheduled on these platforms, its running time can be inferred directly. However, these historical records are the static snapshots with previous setups, which is difficult to fit into a complicated network computing environment.</p><p>The model-driven prediction does not rely on any specific result on a real platform. Instead, it builds the performance models for the computing platforms and applications. Then, the running time is predicted by calculating and analyzing these models. This method needs to understand the implementations of applications and features of the hardware in detail. If the model is not accurate, the real execution time may have large conflicts with the predicted one. Besides, a heterogeneous and shared network complicates the real prediction. Even worse, predicting some features of platforms (such as network traffic) is still an open problem <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>.</p><p>The most promising solution is benchmarking. If we can find a "representative" benchmark that exercises the application's characteristics, we can use the benchmarking results to quantify the application performance on different platforms. If we simply rely on the limited benchmark library, it is almost impossible to find a "representative" one since real applications are diverse.</p><p>In this paper, we present DwarfCode, a tool that can accurately predict multicore systems include process-level coarse (MPI) application performance. We focus on MPI applications because they are the most popular types of HPC applications and their behaviors are well understood. This method can be easily extended to the HPC or Cloud computing environments. The key idea is to use computation and communication traces as a platform-independent abstraction of real application behaviors-Dwarf-Code captures the computation and communication traces of an executing application using a lightweight tracing engine, analyzes these traces, and then generates a "dwarf code" automatically. The dwarf code is a shorter running benchmark of the real application which mimics the behavior the application. Its running time is expected to be proportional to that of the original program on platforms with a similar architecture. Finally, the dwarf code can be replayed on a target platform to predict the application's performance.</p><p>The modules of DwarfCode include trace recording, trace merging, repeat compression and dwarf code generation. Although several related studies have been conducted and well-grounded in trace recording and code generation <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, challenges remain in trace merging and repeat compression. In order to accomplish this, first, we need to tackle function conflicts in trace merging with lower time complexity. Second, we need to develop a lower time complexity algorithm for repeat compression attacking the existing O(n 3 ) algorithm. Finally, DwarfCode is fulfilled and evaluated on small-scale and large-scale platforms to confirm the prediction accuracy and scalability.</p><p>We have implemented DwarfCode, developed an O (mpn) trace merging algorithm as well as an O(nlogn) repeat compression algorithm. DwarfCode is deployed on two small-scale clusters (named Dawning1000 and IA32) and one large-scale supercomputer (named Kongfu). We find that DwarfCode can predict the response times of NAS Parallel Benchmarks (NPB) <ref type="bibr" target="#b12">[13]</ref> and Parallel NBody Simulation application with low error rates (&lt;3 percent on Dawning1000, &lt;10 percent on IA32 and on Kongfu). This toolkit has been released for free download on Github <ref type="bibr" target="#b39">[40]</ref> under GNU general public license (GPL) v3.</p><p>The rest of this paper is organized as follows. Section 2 presents the trace recording procedure. We describe the trace merging and repeat compression algorithms in Sections 3 and 4, respectively. Section 5 explains the dwarf code generation. DwarfCode is evaluated in Section 6. Section 7 presents the related works. Architecture and deadlock issues are discussed in Section 8. Section 9 concludes and discusses our work in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TRACE RECORDING</head><p>To generate an execution trace, DwarfCode needs to decide the event types to trace. The CPU, storage, network and lock events are the important events to profile general programs. For MPI applications, the communication and computation events are critical to be recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Recording the Computation</head><p>To record the time for computation operations, DwarfCode measures the time spent between the end of an MPI call and the start of the next MPI call.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recording the Communication</head><p>To record the behaviors of MPI calls, DwarfCode links the MPI application by employing a standard MPI profiling layer (PMPI) <ref type="bibr" target="#b13">[14]</ref>. The PMPI interface is widely used by performance analysis tools and libraries, such as VampirTrace <ref type="bibr" target="#b14">[15]</ref>. DwarfCode uses PMPI to intercept MPI calls during application execution and direct to wrapper MPI calls. When an MPI call is executed, the profiling library intercepts it, and records its parameters and timestamps. Once these are logged, the original MPI routine is invoked. DwarfCode uses a wellknown MPI profiler mpiP <ref type="bibr" target="#b15">[16]</ref> to record the traces. <ref type="figure" target="#fig_0">Fig. 1</ref> shows a fragment of the runtime trace log, which is from NPB BT application (Class C; ProcRank ¼ 0).</p><p>The trace consists of many records with the same data structures. The format of each record is shown as a cell in The values of Starttime and Endtime are logical time. The logical time is the difference of the timestamp of current call relative to the timestamp when the MPI process starts, i.e., when the MPI_Init function is invoked. When an MPI application starts, all the processes will invoke MPI_Init(). At this time, DwarfCode records their timestamps as Global_Init_-Time. Note that the values of Global_Init_Time might be different in different processes. When these processes intercept the start of one new MPI call, they record the difference between current timestamp and the corresponding Glob-al_Init_Time as Starttime. When these processes intercept the end of one new MPI call, they record the difference between current timestamp and the corresponding Glob-al_Init_Time as Endtime. Even so, there might be some errors incurred by the unbalanced or overlapped computation or communication. Only if the deviation of their Starttime/Endtime is below a certain percentage of the error rate, they can be determined as the same logical time. In our experiments, the threshold error rate is set to 8 percent based on experimental analysis.</p><p>The procedure to generate the logical traces is called trace logicalization. A communication matrix that identifies process pairs with traffic during execution is also generated by summarizing the number of messages exchanged between process pairs. Our former studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> leverage the graph isomorphism checking algorithm to identify the application level communication topology. Finally, all message sends and receives are to/from a logical neighbor in terms of a logical communication topology (e.g., a torus or a grid) instead of a physical process rank. The logical communication trace keeps similar behaviors to the physical communication trace, which can make the generated code scalable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TRACE MERGING</head><p>DwarfCode records the traces for separate MPI processes, which may build a family of process-level dwarf codes independently. However, we aim to construct a single SPMD dwarf program to mimic the original program behavior. Thus, the traces from these processes should be merged into a single trace before the dwarf code generation.</p><p>In this section, we propose a trace merging algorithm to combine these similar events. Its main challenges are threefold: 1) How to identify similar events from distinct traces (Section 3.1); 2) How to tackle function conflicts (Section 3.2); 3) How to devise lower time complexity algorithm for trace merging (Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Identifying Similar Events</head><p>Only similar events originated from the same MPI call can be merged in the final single trace. Thus, several rules are proposed to delimit similar events.</p><p>First, similar events should have the same logical time (recorded in Starttime and Endtime domains in <ref type="figure" target="#fig_0">Fig. 1</ref>) and function name (Function domain in <ref type="figure" target="#fig_0">Fig. 1</ref>) in different traces. Clearly, collective and point-to-point communication events should not be merged together because of function name violation; neither should blocking and non-blocking events. Additionally, even for point-to-point communication events with the same logical time and function name, one need to further compare their communication parameters (Parameters and Paravalues domains in <ref type="figure" target="#fig_0">Fig. 1</ref>), e.g., count, source and dest in the MPI_Send and MPI_Recv calls. Only if the communication (e.g., count) deviation is below a threshold, these communication events are considered similar and merged. In our experiment, the deviation threshold is set up as 5 percent based on experimental analysis.</p><p>Finally, as far as computation events are concerned, DwarfCode treats the computation events between the same pair of communication events as similar events. The computational time is determined by the longest trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tackling Function Conflicts</head><p>Function conflicts can be described as one or more of the processes, but not all, invoking certain MPI functions. As shown in <ref type="figure" target="#fig_6">Fig. 2a</ref>, Process 0 invokes MPI_A after MPI_B while other processes only invoke MPI_A. As shown in <ref type="figure" target="#fig_6">Fig. 2b</ref>, this causes that the logical time of MPI_A recorded in Process 0 conflicts with those from the other processes.</p><p>The key to solve function conflicts is to sequence the conflicted calls, align the similar ones and merge them to the extent possible. We propose a maximal m-step downward tracing heuristic to compare the tracing distances of conflicted calls.</p><p>First, when the conflicts happen, each conflicted call individually searches similar calls in all of the remaining traces and records their distances when the first similar call is found. The tracing distance denotes the maximal distance among the recorded ones. For example, <ref type="figure" target="#fig_3">Fig. 3</ref> shows that MPI_B of Process 0 conflicts with MPI_A of other processes in the first line. The tracing distance of MPI_B is 2 because in two steps MPI_B searches down and finds the farthest MPI_B of Process 3 in the third line; Similarly, the tracing distance of MPI_A is 3 because MPI_A of Process 2 in the last line is the farthest match. Note that an upper bound m should be set for the tracing distance. Otherwise, some unrelated calls may be merged incorrectly. According to the experiments, m is set up as 10. The unrelated calls are merged correctly, only if the tracing distance is less than m ¼ 10; otherwise, the merge of the unrelated calls is incorrect.</p><p>Then, we sequence the conflict calls in descending order of their tracing distances. For example in <ref type="figure" target="#fig_11">Fig. 4a</ref>, MPI_B of process 0 conflicts with MPI_A of the other processes in the first line. Then, we compute the tracing distances of MPI_B and MPI_A individually. MPI_A can be merged in the next line, thus its tracing distance is 1. However, MPI_B cannot be merged until the end of the trace, thus its tracing distance is m (the upper bound). Because m is greater than 1, MPI_B should be in front of MPI_A in the merged trace. The same procedure is also suitable for MPI_D and MPI_C. <ref type="figure" target="#fig_11">Fig. 4b</ref> illustrates the result of the merged trace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Trace-Merging Algorithm</head><p>The number of events recorded in the traces can be very large. For example, the events of the LU application from NPB 3.3 are up to 10 6 . Thus, more scalable algorithms with lower complexity are preferred. DwarfCode introduces a new trace-merging algorithm with the overall time complexity of  O(mpn), where m denotes the upper bound of tracing distance, p denotes the number of processes, and n denotes the maximum of event numbers of all the traces. The complete algorithm is shown in Algorithm 1. We initialize the pointers to the top of each trace (lines 1-3). Then, we tackle the function conflicts and merge similar events (lines 4-21). If the corresponding events can be merged without function conflicts, they are simply joined into the final trace. Otherwise, the tracing distance is calculated, and the maximal tracing distance is merged with time complexity O(mpn). Thus, the overall time complexity of Algorithm 1 is O(mpn).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Trace-Merging Algorithm</head><p>Input: T-a set of all the traces Output: F-the merged trace. Variables: p-the number of traces in T n-the maximum of event numbers of all the traces t i -the ith trace (a set of events from process i), where 0 i p, t i 2 T l i -the location of current event required to be merged in the t i , where 0 l i n m-the upper bound of tracing distance d k i -the tracing distance of the kth</p><formula xml:id="formula_0">event of t i 1. foreach 0 i p do 2. l i ¼ 0 3. endfor 4. repeat 5.</formula><p>If the events pointed by all the l i can be merged, then 6.</p><p>merge the events and insert the merged events to the bottom of F 7.</p><p>foreach The time complexity of trace merging algorithms can be further reduced to O(mnlogp) if a parallel trace merging architecture is introduced. This advanced architecture is used in Scalasca <ref type="bibr" target="#b48">[49]</ref> and VampirServer <ref type="bibr" target="#b50">[50]</ref> with Open Trace Format 2 (OTF2). First, our system loads the trace files into memory. Then, trace files are bisected and recursively merged based on Algorithm 1. Finally, all trace files are meged into a single trace in parallel.</p><formula xml:id="formula_1">0 i p do 8. l i ¼ l i þ 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">REPEAT COMPRESSION</head><p>After gaining the merged trace, the core of DwarfCode is to identify and compress the repeating patterns in the final trace to shrink the size of the events. The purpose of repeat compression is two-fold: 1) the computation and communication events inside a loop are spread out during the trace recording. These loops should be discovered and folded again; 2) to downsize the size of the original program to generate the dwarf code; the similar and successive events are also recognized and compressed even if these events are not in the same loop.</p><p>In this section, first, the repeat compression problem is formulated into an optimal string compression problem. Then, the key is two-fold: 1) find all the primitive and inextensible tandem (PIT arrays) arrays; 2) find the optimal combination of tandem arrays to acquire the optimal compression of the original string. After solving the two sub-problems, the repeat compression algorithm is provided and its complexity is analyzed in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Formulation</head><p>The merged trace can be converted into a string of symbols. Each event with the similar function is represented with the same symbol. The similarity of the events is determined as stated in Section 3.1. Then, the merged trace is symbolized as a string S with a finite alphabet of a fixed size, such as: S ¼ xyaxyabcdabcdabcdae. The aim of repeat compression is to discover and shrink the loop nest structures or similar successive events. Thus, the repeat compression problem can be converted into finding and reducing the repeating substrings in S.</p><p>Repeating substrings are divided into three categories: 1) a tandem repeat means two successive identical substrings immediately follow each other (such as abcabc, abc is the repeat substring); 2) an overlap repeat means two identical substrings overlap (such as abaabaab, abaab is the repeat substring); 3) a split repeat means two identical substrings are separated by some nonempty substring (such as abcdeabc, abc is the repeat substring). Note that a loop structure in the trace is the same as a tandem repeat in the string. Thus, we are only interested in finding the tandem repeats. The overlap and split ones are omitted.</p><p>Specifically, if a tandem repeat does not contain shorter repeats, it is called a primitive tandem repeat. A tandem repeat is inextensible if there is no identical substring immediately before or after the repeats. For instance, if the string is represented as ðababÞ 2 , the repeat ðababÞ 2 is not primitive for containing the shorter repeat ab. If the string is represented as ðabÞ 3 ab, the repeat ðabÞ 3 is not inextensible for an identical substring after it.</p><p>We define the trace length after the compression as the metric to evaluate the optimal compression. The shorter the length, the better the compression. For example, consider the string xyaxyabcdabcdabcdae. There exist two primitive and inextensible compressions ðxyaÞ 2 ðbcdaÞ 3 e and xyaxyðabcdÞ 3 ae. The former's length is 8, and the latter's one is 11. Moreover, more than one compression may be optimal. For example, consider the string abcabcabca. Both ðabcÞ 3 a and a ðbcaÞ 3 are optimal.</p><p>Before formulating the repeat compression problem more precisely, we introduce the terminology on the string. Definition 2. A tandem array denotes a substring S½i::iþ jaj Â p À 1 in S where S½i:</p><formula xml:id="formula_2">:i þ jaj Â 1 À 1 ¼ S½i þ jaj::i þ jaj Â 2 À 1¼Á Á Á¼S½i þ jaj Â ðp À 1Þ::iþjajÂp À 1, i ð1 i n)</formula><p>is the starting symbol, að1 jaj nÞ is the repeated substring, and pð2 p nÞ is the repeated periods of a. For simplicity, it is denoted by a triple (i, a, p). If p ¼ 2, (i, a, 2) denotes a tandem repeat. A tandem array is primitive if and only if a is not periodic. A tandem array is inextensible if and only if there is no a right before or after the tandem array. P ¼ fði; a; pÞj1 i, jaj n; 2 p n, (i, a, p) is primitive and inextensible} denotes the set of the primitive and inextensible tandem arrays.</p><p>Definition 3. A compression of a string S denotes a tandem array set C i 2 2Sð1 i j2SjÞ, which compresses the original string S into S i . C i is an optimal compression if and only if 8j 1 j j2Sj; jS i j jS j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Problem 1. The Optimal String Compression Problem</head><p>Query. In a string S, find a combination set C j of the primitive and inextensible tandem arrays, which provides an optimal compression solution S i : C j 2 2S; P ¼ fði; a; pÞ j 1 i; j a j n; 2 p n; ði; a; pÞ is primitive and inextensible}.</p><p>The methodology to solve the OSC problem is two-fold: 1) find all the primitive and inextensible tandem arrays (i, a, p) in the string and form a set P of the tandem arrays; 2) find the optimal combination C i of the tandem arrays from P to acquire the optimal compression of the original string.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Finding the Primitive and Inextensible Tandem Arrays</head><p>The computation of all the primitive and inextensible tandem arrays is a classical string matching problem with various application areas, most notably molecular biology <ref type="bibr" target="#b16">[17]</ref>. There are several different O(nlogn) algorithms finding all the PIT arrays. In 1981, the problem is first studied by Crochemore <ref type="bibr" target="#b17">[18]</ref> and an optimal O(nlogn) algorithm is given. In recent years, most of the algorithms are based on the suffix tree. Apostolico and Preparata <ref type="bibr" target="#b18">[19]</ref> present an O(nlogn) algorithm for finding the leftmost PIT arrays. Main and Lorentz <ref type="bibr" target="#b19">[20]</ref> propose another algorithm which actually finds all PIT arrays in O(nlogn) time. The algorithms based on the suffix tree are efficient, but building and processing the suffix tree with several auxiliary data structures consume much memory <ref type="bibr" target="#b20">[21]</ref>. In this section, we design an O(nlogn) algorithm based on the suffix array. Its advantage over the suffix tree is that, in practice, they use three to five times less memory.</p><p>The idea of our algorithm is based on the Theorem 1 derived by us and the Theorem 2 mentioned in <ref type="bibr" target="#b21">[22]</ref>. Proof. Refer to <ref type="bibr" target="#b21">[22]</ref>.</p><p>t u</p><p>The complete algorithm for finding all the PIT arrays is shown below: if ðS½j 6 ¼ S½j þ lÞ then continue 5.</p><p>else</p><formula xml:id="formula_3">L p ¼ Longest_Common_Prefix(jþ1, l) 6. L s ¼ Longest_Common_Suffix(j, l) 7. endif 8. if (ðL p þ L s Þ ! lÞ 9. P S[(j À L p )..(j þ l þ L s )] 10. endif 11. endfor 12. endfor</formula><p>In Algorithm 2, the length of the complete string is j S j ¼ n (line 1). For each tandem array (i, a, p) in S, the length l ¼ jaj must not exceed n/2 because the repeated periods of a are greater than 1. Then, we enumerate the 1 l n=2 to find all the tandem arrays (i, a, p) where j a j ¼ l (lines 2-12). For a fixed l, first, we find a certain position j where S½j ¼ S½j þ i (line 3). Then, we calculate the longest common suffix (LCS) and prefix from the S[j] and S[j þ l] (lines 5-7). Finally, if the sum of the prefix and suffix is greater than l-1, then we find a tandem array where jaj ¼ l and record it (lines 8-10).  To reduce the time complexity of Algorithm 2, the key is to reduce the time of the longest common prefix and suffix (lines 5-6). The LCS and LCP problem can be converted into the Range Minimum Query (RMQ) problem. We use a fast (O(n), O(1)) time algorithm for the RMQ problem, which can also be applied to the LCS and LCP problem <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>. The O(n) is the preprocessing time to construct the suffix array, and the O(1) is the query time to find the longest common prefix and suffix based on the preprocessed suffix array. The complete (O(n), O(1)) algorithm for the LCP and LCS program is detailed in <ref type="bibr" target="#b22">[23]</ref>. The suffix array is the basic data structure for the LCP and LCS problem.</p><p>The suffix array is the basic data structure for the LCP and LCS problem. We define the suffix array of a string S as a pair of arrays (SA, Rank). The sort array SA is the lexicographically ordered list of all suffixes of S. That is, SA[i] ¼ j if suffix (j) is lexicographically the ith suffix among all suffixes suffix (1), suffix(2),. . ., suffix(n) of S. The number of i will be called the rank of suffix(j), denoted by Rank(j) ¼ i, which is an inverse with the SA. That is, SA[Rank[j]] ¼ j. We adopt the DC3 algorithm <ref type="bibr" target="#b24">[25]</ref> to construct the suffix array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Finding the Optimal Combination of Tandem Arrays</head><p>After finding all the PIT arrays of the string S ( j S j ¼ n), we acquire a set P ¼ fði; a; pÞj1 i, jaj n, 2 p n, (i, a, p)</p><p>isprimitive and inextensible}. The next step is to find a subset</p><formula xml:id="formula_4">C i 2 2S so that 8 j 1 j j2Sj, jS i j jS j j if the string S is compressed with C i .</formula><p>The maximal number of all the PIT arrays is O(nlog(n)) <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> for a string jSj ¼ n. The time complexity to enumerate all the solutions is Oð2 n logðnÞ Þ, which is an NP hard problem. Thus, we aim to provide a heuristic algorithm for near-optimal solution.</p><p>An Oðn 3 Þ dynamic programming algorithm can be easily designed to find the near-optimal combination of tandem arrays. However, the complexity needs to be reduced further. Xu and Subhlok <ref type="bibr" target="#b7">[8]</ref> propose a greedy heuristic called "Bottom-Up" to iteratively choose the longest PIT array with the smallest starting point. The time complexity is Oðn 2 Þ while there exists the risk of missing the optimal solution. For example, the PIT arrays are {(1, xya, 2), (6, abcd, 3), (7, bcda, 3)} for a string S ¼ xyaxyabcdabcdabcdaef. According to the "loop filtering" algorithm, we can get the C i ¼ fð6; abcd; 3Þg to acquire the compressed string S' ¼ xyaxy(abcd) <ref type="bibr" target="#b2">3</ref> aef and j S 0 j ¼ 12. Obviously, the optimal solution is S} ¼ The advantage of Algorithm 3 lies in the non-overlapping detection of PIT arrays (lines 5-11). First, when the first longest PIT array (i, a, p) is chosen, the values from mark[i] to mark[iþ j a j Âp-1] are set as True. Then, when the next PIT array (j, b, q) is chosen, we should judge whether the value of mark[j] or mark ½j þ jbj Â q À 1 has been set as True. If either one is True, the PIT array (j, b, q) is overlapped with former selected PIT arrays and this PIT array should be discarded. Otherwise, we add the PIT array to the final combination of PIT arrays and set the values from mark[j] to mark ½j þ jbj Â q À 1 as True.</p><p>The time complexity of the non-overlapping detection of PIT arrays (lines 5-11) is O(1). First, choosing the longest PIT array (line 5) is O(1) because the PIT arrays have been sorted according to their lengths in line 3. Then, comparing the two endpoints (lines 6-8) is O(1). Finally, the marking procedure (lines 9-11) is O(1). Although the marking procedure seems to scan and mark the Boolean array O (nlg(n)) times, we should note that not every PIT array needs to scan and mark the Boolean array. Because the length of the Boolean array is n, in the worst case it should be marked O(n) times. While the total iteration number is O(nlog(n)), according to the amortized analysis, the amortized time complexity for each iteration in lines 9-11 should be O(1). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3. The Greedy Selection Algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Repeat Compression Algorithm and Complexity Analysis</head><p>The complete repeat compression algorithm is shown in Algorithm 4. First, the string S ( j S j ¼ n) is converted into the suffix array with the DC3 algorithm (line 2). Then, we use the Range Minimum Query algorithm to preprocess the suffix array (line 3). Third, Algorithm 2 is introduced to find all the PIT arrays (line 4). Finally, Algorithm 3 is used to greedily select and order the sequences of the PIT arrays (line 5). The procedure mentioned above repeats until the set of PIT array is empty (line 8).</p><p>The time complexity of the repeat compression algorithm is O(nlog(n)), which is proved by the following lemmas and theorems. Lemma 1. The time complexity of Algorithm DC3 is O(n).</p><p>Proof. Refer to <ref type="bibr" target="#b24">[25]</ref>. Proof. Refer to <ref type="bibr" target="#b23">[24]</ref>. t u Lemma 3. The time complexity of Algorithm 2 (All the PIT Arrays Finding Algorithm) is O(nlogn).</p><p>Proof. The outmost loop number l of Algorithm 2 is from 1 to n/2. The inner loop number is n/l. Thus, the total iterative number is P ¼ n=1 þ n=2þ; . . . ; þn=ðn=2Þ ¼ nð1þ 1=2þ; . . . ; þ2=nÞ &lt; nð1 þ 1=2þ; . . . ; þ1=nÞ ¼ nH n , where H n ¼ 1 þ 1=2þ; . . . ; þ1=n. Note that the sum of the reciprocals of the first n natural numbers H n is the nth harmonic number. The sum H n is approximated by the integral R n 1 1</p><p>x dx, whose value is log(n). Thus, P &lt; n H n nlogn. Also, the loop body is LCP and LCS. Note that in Lemma 2, the query time of LCP and LCS is O(1). Thus, the time complexity is determined by the iterative number, whose upper bound is O(nlogn).</p><p>t u Proof. Note that the maximal number of all the PIT arrays found by Algorithm 2 is nlogn <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. In Algorithm 3, each PIT array is traversed once and the amortized complexity for each traverse is O(1). Thus, the time complexity of Algorithm 3 is O(nlogn). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">GENERATING DWARF CODE</head><p>The final step to build the dwarf code is to convert the merged and compressed trace into an executable program, which mimics the behavior represented in the trace. The compressed trace in this phase contains the primitive tandem arrays with the loop numbers. These arrays consist of a series of symbols, which denotes an MPI communication call or a computation in a certain period. The trace is converted into the executable C dwarf code by resuming these symbols with the communication or computation calls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tackling the Computation</head><p>We can replace the symbols representing computation by synthetic computation codes with equal duration time, such as the busy waiting or spinning, to generate the dwarf code.</p><p>The iteration number (abbreviated as IN, IN &gt; 1) of the loop can be adjusted with the predefined compression ratio (abbreviated as CR, 0 &lt; CR &lt; 1). For example, a computation symbol can be replaced by the following loop statement, where the iteration number is multiplied by compression ratio to decrease the running time in proportion:</p><formula xml:id="formula_6">for ði ¼ 1; i &lt;¼ IN Ã CR; i þ þÞfg;</formula><p>However, busy waiting or spinning is an inefficient programming pattern and should be avoided. Also, it might be removed by modern compilers as dead codes. As an alternative, we can use a delay function (e.g., sleep ()) found in most operating systems. This puts a process to sleep for a specified time, during which it will waste no CPU time. For example, a computation symbol can be replaced by the following loop statement: sleep (Original Runtime Ã CR); S Compress S with C 7. until ( P is empty) 8.</p><p>S 0 S</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Tackling the Communication</head><p>In the trace recording and merging phases, the algorithm preserves the src and dest information of point-to-point communication. The dwarf code needs to restore these parameters. In order to unify the dwarf code, first we obtain the rank of the current process immediately after executing the MPI_Init call, and save it in a global variable id_proc. Before each point-to-point communication call performs, we create a src/dest matrix according to the merging information recorded, and then invoke the communication calls. The parameters in the corresponding positions can be obtained according to the value of id_proc in the assignment matrix. <ref type="figure" target="#fig_14">Fig. 6</ref> illustrates the procedure of one-to-one communication in BT's dwarf code. The parameter count can be adjusted to scale down the running time of the dwarf code proportionally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Tackling the PIT Arrays</head><p>The PIT arrays (i, a, p) are converted into the loop statements. The repeat number p is converted into the loop number. The primitive substring a is mapped to the corresponding computation and communication calls. The repeat number (or loop number) p can be adjusted to scale down the running time of the dwarf code in proportion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiment Setup</head><p>To evaluate the correctness and efficiency of the Dwarf-Code system, we perform extensive experiments with NAS parallel benchmarks on two small clusters named "Dawning1000" and "IA32", and one large cluster named "Kongfu" with different sizes, architectures, interconnection types, and operating systems, as described below:</p><p>Dawning1000 is a 16-node tightly coupled cluster. All experimental results are based on the MPI implementation of the NPB and a real application-Parallel NBody Simulation. The NPB includes eight benchmarks mimic the computation and data movement in CFD applications. Five are kernels: IS, EP, CG, MG, and FT. Three are pseudo applications: BT, SP, and LU. We construct the dwarf codes for each Class C benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Validation of Trace Recording</head><p>The aim is to check whether all the computation and communication events can be recorded, especially the communication calls. Note that the number of events recorded in different traces, even from the same application, might not be the same. This is due to the unstructured point-to-point communication that can cause unbalanced communication. Thus, we record and compare the largest and smallest number of communication events from the traces of NPB applications. <ref type="table" target="#tab_3">Table 1</ref> shows the number of communication events recorded running eight NPB applications in Dawning1000. By comparing the recorded communication events with the MPI statements in their source codes, we verify that all the events are completely recorded. We run NPB applications from Class A to F. We find the number of communication events are approximately equal to each other while the running times change dramatically. Thus, we choose Class C (the middle size) to continue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Validation of Trace Merging</head><p>In this section, the aim is to check whether the merged trace maintains the original computation and communication behaviors. Also, we evaluate the running time of the trace merging algorithm. <ref type="table" target="#tab_4">Table 2</ref> shows the number of merged traces and the merging time when running eight NPB applications in Dawning1000. The trace merging algorithm can successfully regularize and merge the traces, and the number of merged traces in <ref type="table" target="#tab_4">Table 2</ref> is identical to the maximal number of the communication events in <ref type="table" target="#tab_3">Table 1</ref>. The merging time is much faster than the running time of NPB applications. The longest merging time LU is 375.84 seconds, which is far less than the running time of LU application itself.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Validation of Repeat Compression</head><p>In this section, the aim is to evaluate the compression ratio and the compression time of the repeat compression algorithm.</p><p>The compression is affected by the loop number. The NPB applications are scientific computing applications and the loop structure dominates the main body in most of them. However, the traces of the EP, FT and IS applications are so small that we omit their results. Because enumerating all the inner and outer loops is complicated, we focus on the outer loops. <ref type="table">Table 3</ref> shows the main loop structure, original length, compressed length and compression ratio of BT, CG, LU, MG and SP applications. The main loop structures are represented by the product of the loop number and the statement number of each loop, i.e., <ref type="bibr" target="#b14">(15)</ref> Â 200 denotes that the statement number inside the loop is 15 and the loop number is 200 for the BT application. The compress ratios are very high even the lowest compress ratios of MG is 96.9 percent and the highest one of LU is 99.998 percent.</p><p>In order to further evaluate our repeat compression algorithm, we compare it with a "Top-Down" algorithm in <ref type="bibr" target="#b7">[8]</ref> and a "Bottom-Up" algorithm in <ref type="bibr" target="#b8">[9]</ref> for compressed length and running time. <ref type="table">Table 4</ref> shows that when the initial trace lengths are small such as the BT, CG, MG, and SP applications, their compressed lengths with our algorithm are the same as those with the "Top-Down" and "Bottom-Up" algorithms. However, when the initial trace length is large such as the LU application, the compressed length with our algorithm is shorter than that with other algorithms. <ref type="table" target="#tab_5">Table 5</ref> shows that the running time of our algorithm is shorter than that of the "Top-Down" and "Bottom-Up" algorithms for all NPB applications. The "Top-Down" algorithm is the most time-consuming. The running time of our algorithm is 50 percent shorter than that of the "Bottom-Up" algorithm for most applications. <ref type="table" target="#tab_5">Tables 4 and 5</ref> do not list the result of the "Top-Down" algorithm for the trace of LU. The reason is that its time of compressing LU with the "Top-Down" algorithm is too long and far beyond 10 5 seconds.</p><p>The time complexity of our algorithm is O(nlogn) while the time complexity of the "Top-Down" and "Bottom-Up" algorithms is Oðn 2 Þ. Therefore, our algorithm shows much better asymptotic time complexity than two other algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Validation of Prediction Accuracy</head><p>The aim is to evaluate the prediction accuracy of the dwarf code. We generate the dwarf codes of BT, CG, LU, MG and SP application with Class C on Dawning1000. The dwarf codes that are generated are 10 times smaller than the original programs. Then, the original programs and dwarf codes run separately on Dawning1000 and IA32 clusters with all of 16 nodes. <ref type="table">Table 6</ref> shows the actual running time of the original program, the running time of the dwarf code, the predicted time of the dwarf code and the error rates on Dawning1000. <ref type="table" target="#tab_6">Table 7</ref> shows the results on IA32.</p><p>As for Dawning1000, the prediction error rates are less than 3 percent for 5 NPB applications; As for IA32, the error rates do not exceed 10 percent. The prediction difference between Dawning1000 and IA32 cluster is that IA32 is a  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Validation of Scalability</head><p>To verify the scalability of DwarfCode, real applications were deployed on modern hardware with fast processors and low latency networking. The scalability is measured on the KongFu high performance cluster, which is installed at the High Performance Computing Center in Harbin Institute of Technology.</p><p>Parallel NBody Simulation is introduced as a real application. The NBody application aims to predict the motion of a great number of celestial objects that interact with the gravitation and repulsion force. The code of the application is acquired from the Petascale Education Program supported by the NCSA Blue Waters project <ref type="bibr" target="#b25">[26]</ref>. The parallel version contains approximately 3,000 lines of codes, which is written in C plus MPI. The input parameter body number is important to determine the computing time and will be equally divided into different nodes. In the following experiments, the number of bodies is set to 256 K, which is an upper bound size to fit the memory of each node. The dwarf code of Parallel NBody Simulation is generated from the traces on 16 cores. <ref type="table">Table 8</ref> shows results when the application runs on the four, eight and 16 cores. The error rates are approximately 20 percent. However, when it runs on the 32, 64, 128 and 256 cores, the error rates are no more than 10 percent. By analyzing the utilization of memory and swap spaces, we find that when the application runs on the four, eight and 16 cores, it uses more RAM than is physically available and the paging procedure consumes more time than expected. However, when the number of cores is greater than 32, the memory is sufficient while the computing and communication parts dominate the running time. Thus, the error rates are under 10 percent and the scalability can be verified.</p><p>The Finally, when we generate the dwarf code, we make sure to correctly recover the parameters comm, count, datatype and op.</p><p>To verify the DwarfCode's scalaibity for the collective communication, we summarize the collective calls invoked by the NPB and Nbody applicatons. <ref type="table" target="#tab_7">Table 9</ref> shows that most of common collective operations are covered and the generated dwarf codes work well, including MPI_Bcast, MPI_Gather, MPI_Scatter, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATED WORK</head><p>Relevant previous projects mainly focus on finding the benchmark most similar to an application to predict performance. In 1989, Cole originally puts forward the Algorithmic Skeletons <ref type="bibr" target="#b26">[27]</ref> by designing the program template for several frequently used parallel programs. In 1993, Dikaiakos et al. <ref type="bibr" target="#b27">[28]</ref> extend the simulation scale of parallel programs through the method of functional algorithm simulation. They build a FAST prototype which collects external information to forecast the performance of massively parallel programs. In 1999, Dinda and Hallaron find that the running time of applications is closely relevant to the workload <ref type="bibr" target="#b28">[29]</ref>. Hoste et al. <ref type="bibr" target="#b29">[30]</ref> describe architecture independent characteristics to find the most similar benchmarks to predict the performance of CPU-intensive  applications. Lu and Reed <ref type="bibr" target="#b30">[31]</ref> propose a method using curve fitting to compress parallel programs for reducing the program running time significantly. Sherwood et al. <ref type="bibr" target="#b31">[32]</ref> study automatic analysis of the periodicity of parallel programs. Also, some works focus on predicting web application's performance through modeling <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. In contrast to DwarfCode, these approaches rely on the library of existing benchmarks, which neglect the diversity and complexity of applications and platforms.</p><p>HPC simulators, such as SST <ref type="bibr" target="#b40">[41]</ref>, BigSim <ref type="bibr" target="#b41">[42]</ref>, ROSS <ref type="bibr" target="#b42">[43]</ref>, and PSINS <ref type="bibr" target="#b43">[44]</ref>, can allow simulation of diverse aspects of hardware and software. But the prediction accuracy of the application running time is reduced for loss of details in modeling process. Our system automatically generates the dwarf code, a customized benchmark, which can be replayed in real-time without modeling either the application or the platform.</p><p>Some recent attempts aim to generate a shorter running benchmark of the real application and replay it on the target platform. CloudProphet <ref type="bibr" target="#b34">[35]</ref> is an end-to-end performance prediction tool for web applications in the cloud. It replays the trace log by capturing the resource usage and extracting the dependency. CloudProphet only focuses on web applications while DwarfCode pays close attention to MPI applications.</p><p>Several studies address performance prediction for MPI applications. Dimemas <ref type="bibr" target="#b4">[5]</ref> is a performance prediction tool for MPI applications in the Grid environment. It captures the CPU bursts and the communication patterns. It models the target architecture with a configuration file. Meanwhile, Sodhi et al. <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> propose a framework for automatic generation of performance skeletons. Xu et al. <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> present generation of coordinated performance skeletons, similar to dwarf code with logicalization and compression procedures. Parallel application signatures for performance prediction (PAS2P) is a tool studied by Wong et al. <ref type="bibr" target="#b9">[10]</ref>. Based on the application's message-passing activity, representative phases can be identified and extracted, with which a parallel application signature can be created to predict the application's performance. Mueller et al. <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref> introduce intra-node and inter-node compression techniques of MPI events that are capable of extracting an application's communication structure and presenting an automatic generation mechanism for replaying the traces. Chen et al. <ref type="bibr" target="#b37">[38]</ref> implement a performance prediction framework, called PHANTOM, which integrates the computation-time acquisition approach with a trace-driven network simulator. Also, part of our preliminary work to build the representative benchmarks is shown in <ref type="bibr" target="#b38">[39]</ref>.</p><p>These approaches are the closest to the DwarfCode work presented in this paper. However, there are some key differences:</p><p>1. Trace merging. Several studies, for example, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, have been conducted on trace merging algorithms but they all have some pitfalls. Sodhi et al. <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> put forward the methods to identify and cluster similar events without considering sequence differences and function conflicts. Xu et al. <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> match communication patterns with application communication graphs represented by the matrices.</p><p>The upper complexity bound of the graph spectrum and isomorphism algorithms is Oðn 3 Þ for n events in each trace. Moreover, it neglects function conflicts. Mueller's studies in <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref> maintain a dependence graph during the entire merge algorithm. The upper complexity bound of the overall merge operation is Oðn 2 Þ for n events in each trace. DwarfCode not only considers the sequence differences and function conflicts, but also reduces the time complexity of the trace merging algorithm to O(mpn). 2. Repeat compression. Related approaches suffer high time complexity for the repeat compression algorithm. Sodhi et al. <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref> recognize and compress repeated execution behaviors as loops to generate the final execution skeleton. The complexity of their compression algorithm is Oðn 3 Þ. Xu et al. <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> take a variant approach to identify the loop structures in a trace based on the Crochemore's algorithm <ref type="bibr" target="#b17">[18]</ref>. The complexity of this compression algorithm is Oðn 2 Þ. Wong et al. <ref type="bibr" target="#b9">[10]</ref> introduce a pattern identification algorithm to find the most relevant phases of the parallel applications, whose complexity is Oðn 2 Þ. Mueller et al. <ref type="bibr" target="#b11">[12]</ref> propose intra-node and inter-node compression techniques of MPI events that are capable of extracting an application's communication structure. Its complexity is Oðn 2 Þ. DwarfCode introduces a novel repeat compression algorithm based on suffix arrays whose time complexity is O(nlogn).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSIONS</head><p>DwarfCode is mainly designed for performance prediction of MPI applications on cluster systems but its principle can aid performance prediction for hybrid MPI þ OpenMP applications on multicore systems and hybrid MPI þ GPU applications on hybrid-core systems with hardware accelerators.</p><p>1) Hybrid MPIþOpenMP applications on MPI and loop-level grain (OpenMP) parallelism. Its running time is the sum of intra-node OpenMP and internode MPI call costs by considering overlapping factor <ref type="bibr" target="#b44">[45]</ref>. Our method can help build parameterized communication model for inter-node MPI calls. Intra-node OpenMP performance can be acquired by analysizing the memory bandwidth contention. 2) Hybrid MPI þ GPU applications on hybrid-core systems conform to a classic MPI þ GPU or GPU-integrated MPI models (MPI-ACC <ref type="bibr" target="#b45">[46]</ref> and MVAPICH-GPU <ref type="bibr" target="#b46">[47]</ref>). For the classic MPI þ GPU model, similar to hybrid MPI þ OpenMP, its running time is the sum of MPI calls between hosts and data copies, which are performed between main memory and the local GPU's device. We can leverage our method for inter-node MPI calls and calculate the costs of cuda-Memcpy or clEnqueueWriteBuffer for data copies. For the GPU-integrated MPI model, the programmer can use the GPU buffer directly as the communication parameter in MPI routines. This is difficult to create the dwarf code, which needs further investigation. Due to event reordering and potential information loss caused by inter-process trace merging, the code generated from traces may have deadlocks. The key issue in ensuring deadlock freedom is to identify and label the non-matching calls.</p><p>1) A procedure is outlined to mark the non-matching calls in our former work <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. It is based on the basic deadlock free patterns which are a) a nonblocking Send/Recv with a matching Recv/Send before a corresponding Wait; b) One or more blocking Send/Recv calls followed by matching Recv/ Send calls. Such calls are labeled with our algorithm in <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> and ignored for code generation. 2) We also solve this with the help of MPI runtime error detection tool, named marmot umpire scalable tool (MUST) <ref type="bibr" target="#b47">[48]</ref>. MUST can cover various process-level correctness checks. It is especially skilled in deadlock detection. We introduce the following steps to ensure the correctness of the final dwarf code: a) run the dwarf code and intercepts all MPI calls of all processes at runtime; b) generate a message dependence graph (MDG) or a wait-for graph (WFG); c) perform type matching, collective verification, and deadlock detection with a centralized deadlock detector with MUST. MUST's AND È OR model can achieve sublinear analysis time. Trace recording needs further improvement to reduce the trace size. Our approach collects raw communication traces for each process of a parallel application. Size of the uncompressed process-level trace usually increases with the number of communication calls. When the number of calls is too large, the size of the raw trace may exceed the storage capacity of a single node. However, there are three ways to alleviate this problem: 1) the trace can be stored in HPC storage system instead of the node generating the trace; 2) the records in the trace can be represented with the binary code but not current ASCII code; 3) online trace merging can be introduced when the trace length is more than the trace distance, thus not waiting for all the traces generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSIONS</head><p>Model-driven and trace-driven performance prediction techniques are of limited use in practice. We present Dwarf-Code, a performance prediction tool for MPI applications. It includes procedures for trace recording, trace merging, repeat compression, and dwarf code generation. Researchers can download our toolkit for free, which is under a GNU GPL v3 license. Our main contribution is three-fold: 1) An O (mpn) trace merging algorithm is proposed, which can also tackle the sequence differences and function conflicts. 2) A novel repeat compression algorithm based on suffix trees is designed, whose time complexity is O(nlogn). It converts the original problem into an optimal string compression problem. First, we find all the primitive and inextensible tandem arrays. Then, we acquire the optimal combination of the tandem arrays to form the solution.</p><p>3) The dwarf code can be built on fewer cores and predict running time of the application on clusters with a similar architecture but more cores. The results show that DwarfCode can accurately predict the running time of MPI applications. The error rate is less than 10 percent for computing and communication intensive applications.</p><p>Current research mainly focuses on modeling the computation and communication, which are typical events of scientific applications, such as NPB applications. However, more complicated and irregular codes should be considered. Future work includes addressing memory and I/O intensive codes and validation with complete multi-phase applications. We are porting the MpiBlast, and SPH applications to our platform.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Each record contains several domains including Rank, Function, Parameters, Paravalues, Starttime, Endtime and Durtime. Rank records the process running the code. Function is the function name of the intercepted MPI call. Parameters and Paravalues record the parameter names and values of the intercepted MPI call, respectively. Starttime and Endtime are the starting time and the ending time of the call, respectively. Durtime is calculated on the difference of Starttime and Endtime.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fragment of running traces (BT, Class ¼ C, ProcRank ¼ 0).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .Fig. 4 .</head><label>24</label><figDesc>Communication that leads to function conflicts. Maximal m-step downward tracing heuristic to tackle the function conflicts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>The case with multiple conflicted calls.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition 1 .</head><label>1</label><figDesc>A string S denotes an ordered list of symbols with a finite alphabet of a fixed size. The length of S is Sj ¼ n. For 1 i j n, S[i..j] denotes the substring of S beginning with the ith and ending with the jth symbol of S. The suffix(i) denotes S[i..n].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Theorem 1 .Theorem 2 .</head><label>12</label><figDesc>If there is a tandem repeat (i, a, 2) in the string S, then 9j 2 f0; jaj; 2jaj . . . ½jSj=jaj Â jajg; S½j ¼ S½j þ jaj.Proof. The length of a tandem repeat (i, a, 2) is 2 j a j , thus there exist j and j þ jaj 2 f0; jaj; 2jaj . . . ½jSj=jaj Â jajg that are covered by the (i, a, 2). Since S½i::i þ jaj Â 1 À 1 ¼ S½i þ jaj::i þ jaj Â 2 À 1 according to Definition 2, then S½j ¼ S½j þ jaj. t u There exists a tandem array with repeat a and j ¼ jaj in the string S ¼ xy, that contains the frontier between x and y and has a root in y if and only ifLCSðjÞ þ LCP ðj þ 1Þ ! j LCS(i) ð1 i nÞ ¼ maxfjjx½m À j þ 1::m ¼ S½m þ i À j þ 1::m þ ig is the longest common suffix LCP(i) ð2 i n þ 1Þ ¼ maxfjjy½1::j ¼ y½i::i þ j À 1g is the longest common prefix (LCP).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Algorithm 2 .</head><label>2</label><figDesc>All the PIT Arrays Finding AlgorithmInput: S-the string denoting the symbolized trace Output: P -a set of all the PIT Arrays Variables: l-the length of each loop body or the repeated substring 1. n ¼ jSj 2. foreach 1 l n=2 do 3. foreach j 2 f0; l; 2 Â l; . . . ; ½n=l Â lg do 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5</head><label>5</label><figDesc>illustrates the procedure to find one PIT array from lines 3 to line 11. The string is S ¼ BABCABCABCDACD, and l ¼ 3. Because in the first loop S[0] 6 ¼ S[3] (line 4), the loop is continued (line 3). Then, because in the next loop S [3] ¼ S[6] ¼ C (line 4), their longest common prefix and longest common suffixare calculated as L p ¼ 2 and L s ¼ 3 (lines 5 &amp; 6). Because L p þ L s ¼ 5 &gt; l ¼ 3 (line 8), one PIT array M ¼ ABCABCABC is identified and added into the set (line 9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Identification of a PIT array in a string.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>2 ðbcdaÞ 3</head><label>3</label><figDesc>ef and jS}j ¼ 9 with C i ¼ fð1; xya; 2Þ, (7,bcda, 3)}. Thus, we propose a new algorithm shown in Algorithm 3. Note that the algorithm only acquires the intermediate results of the final combination. The complete solution relies on Algorithm 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>t u Lemma 2 .</head><label>2</label><figDesc>The time complexity of Algorithm RMQ is (O(n),O(1)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Lemma 4 .</head><label>4</label><figDesc>The time complexity of Algorithm 3 (Greedy Selection Algorithm) is O(nlogn).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>t u Theorem 3 .</head><label>3</label><figDesc>The time complexity of Algorithm 4 (The Repeat Compression Algorithm) is O(nlogn).Proof. The time complexity between repeat (line 1) andUntil(line 7) is O(n) þ O(n) þ O(nlogn) þ O(nlogn) ¼ O(nlogn) based on the Lemmas 1-4. The original string S is compressed to be a new string S ' in line 6. Note that S is shortened at least by half each iteration. Thus, the complexity of Algorithm 4 is O(nlogn) þ O(n/2log(n/2)) þ ,. . ., þ O(1) ¼ O(nlogn). t u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Algorithm 4 .</head><label>4</label><figDesc>The Repeat Compression Algorithm Input: S-the string denotes the symbolized trace Output: S'-the compressed string Variables: SA-the sort array of suffix array Rank-the rank array of suffix array C-a combination of PIT arrays C 2 2S P -a set of all the PIT Arrays 1. repeat 2. (SA, Rank) DC3(S) 3. (SA, Rank) RMQ(SA, Rank) 4. P Finding the primitive and inextensible tandem arrays (SA, Rank) // Algorithm 2 5. C The Greedy Selection ( P ) // Algorithm 3 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 6 .</head><label>6</label><figDesc>Process of parameters of one-to-one communication in BT (CLASS ¼ C, NPROCS ¼ 16)'s dwarf code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 7 .</head><label>7</label><figDesc>Architecture of the IA32 bewolf cluster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>procedure to handle collective communication is shown as follows: First, DwarfCode uses PMPI to intercept the collective calls when they are executed. All the processes involved in the group communication will record the collective calls in their traces. Their parameters are recorded including the buffer (sendbuf &amp; recvbuf), list length (count), data type (datatype), MPI operation (op), MPI communicator (comm). Meantime, the function names and the timestamps are recorded. Then, the collective communication does not need to reorder event sequences unlike the point-to-point communication because the whole communication group is involved in the communication. Third, the procedure of repeat compression is identical with the point-to-point communication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>If two or more PIT arrays satisfy the conditions, choose the one with the smallest starting point.6. if (mark[i] ¼ ¼ True j j mark [i þ j a j Â p À 1] ¼ ¼</figDesc><table><row><cell></cell><cell></cell><cell cols="2">P</cell><cell>according to their lengths in</cell></row><row><cell></cell><cell>descending order</cell><cell></cell><cell></cell></row><row><cell cols="2">4. repeat</cell><cell></cell><cell></cell></row><row><cell>5.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7.</cell><cell>{delete (i, a, p) from</cell><cell cols="2">P</cell><cell>True)</cell></row><row><cell>8.</cell><cell>continue;}</cell><cell></cell><cell></cell></row><row><cell cols="2">9. else</cell><cell></cell><cell></cell></row><row><cell>10.</cell><cell cols="4">{set the value from mark[i] to mark[i þ j a j Â p À 1] as</cell></row><row><cell cols="3">True delete (i, a, p) from 12. until ( 11. P is empty)</cell><cell cols="2">P</cell><cell>and C</cell><cell>C [ fði; a; pÞg</cell></row></table><note>Input: P -a set of all the PIT Arrays Input: S-the string denotes the symbolized trace Input: mark[n]-an array of Boolean type (False/True), whose length is jSj ¼ n Output: C-a combination of PIT arrays, C 2 2S 1. initialization: C 2. foreach 0 &lt; i n do mark[i] ¼ False 3. sort the PIT arrays inchoose the longest PIT array (i, a, p) from P .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>KongFu cluster also has 60 TB external storage. The nodes are interconnected via an Infini-Band 40 Gbits/s network. On all of the clusters, the MPI library is MPICH version 1.2.7 and MPICH 2. The C compiler is gcc 3.4.3, while Fortran compiler is F77. The random number generator is randdp.</figDesc><table><row><cell>Copper-</cell></row><row><cell>mine) 866 MHz processors and 2 GB physical mem-</cell></row><row><cell>ory. The other nodes have dual-core Intel Pentium III</cell></row><row><cell>(Coppermine) 1 GHz processors and 2 GB physical</cell></row><row><cell>memory. The 16 hosts are distributed in four subnets.</cell></row><row><cell>The inner bandwidth is 1 Gb/s while the bandwidth</cell></row><row><cell>between the subnets is 100 Mb/s. Fig. 7 shows the</cell></row><row><cell>architecture of the IA32 bewolf cluster.</cell></row><row><cell>KongFu cluster contains 250 nodes and 1,000-core</cell></row><row><cell>in total. Each node contains a four-core Westmere-</cell></row><row><cell>based Intel Xeon E5620 with a 64-bit instruction set</cell></row><row><cell>and its clock speed is 2.4 GHz. The L1 caches are</cell></row><row><cell>128 KB for codes and 128 KB for data. The L2 and</cell></row><row><cell>L3 caches are 1 and 12 MB, respectively. Each</cell></row><row><cell>node contains 8 GB memory and 2 TB internal</cell></row><row><cell>storage.</cell></row></table><note>Its peak performance achieves 2.5 GFLOPS, and its practical computing speed is 1.58 GFLOPS. It has up to 32 GB memory. Each node has quad-core Intel Xeon(TM) 2.4GHz processors and 2 GB physical memory. The communication network is 1 Gigabit Ethernet. The operating system is Turbo Linux 8.0. IA32 is a 16-node loosely coupled bewolf cluster. Four nodes have dual-core Intel Pentium III (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 1 The</head><label>1</label><figDesc></figDesc><table><row><cell cols="6">Number of Communication Events Recorded</cell><cell></cell></row><row><cell></cell><cell cols="4">in NPB Applications (Class C)</cell><cell></cell><cell></cell></row><row><cell>NPB Application</cell><cell>BT</cell><cell>CG</cell><cell>EP FT IS</cell><cell>LU</cell><cell>MG</cell><cell>SP</cell></row><row><cell>The largest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>number of communication</cell><cell cols="6">17,111 41,954 5 47 38 324,355 10,043 26,891</cell></row><row><cell>events</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>The smallest</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>number of communication</cell><cell cols="6">17,111 41,954 5 47 36 162,189 9,329 26,891</cell></row><row><cell>events</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 2 Results</head><label>2</label><figDesc></figDesc><table><row><cell>of Trace Merging</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 Running</head><label>5</label><figDesc>Time Comparison of Three Algorithms</figDesc><table><row><cell>NPB</cell><cell>Initial</cell><cell></cell><cell cols="3">Time (s)</cell></row><row><cell>application</cell><cell>length</cell><cell cols="4">Our algorithm Top-Down Bottom-Up</cell></row><row><cell>BT</cell><cell>17,111</cell><cell cols="2">4.05</cell><cell cols="2">276.46</cell><cell>6.96</cell></row><row><cell>CG LU</cell><cell>41,954 324,355</cell><cell cols="2">6.81 26.96</cell><cell cols="2">1,498.27 &gt;10 5</cell><cell>7.59 41.87</cell></row><row><cell>MG</cell><cell>10,043</cell><cell cols="2">2.76</cell><cell cols="2">104.84</cell><cell>9.05</cell></row><row><cell>SP</cell><cell>26,891</cell><cell cols="2">5.61</cell><cell cols="2">649.12</cell><cell>10.21</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE 6</cell><cell></cell></row><row><cell cols="6">Results of Time Prediction on Dawning1000 Cluster</cell></row><row><cell>NPB</cell><cell cols="2">Original</cell><cell>Dwarf</cell><cell></cell><cell>Dwarf code</cell><cell>Error</cell></row><row><cell>Application</cell><cell cols="2">program</cell><cell cols="2">code running</cell><cell>prediction</cell><cell>rate (%)</cell></row><row><cell></cell><cell cols="2">running time(s)</cell><cell>time(s)</cell><cell></cell><cell>time(s)</cell></row><row><cell>BT</cell><cell cols="2">1,094.65</cell><cell>113.04</cell><cell></cell><cell>1,130.4</cell><cell>3.27</cell></row><row><cell>CG</cell><cell cols="2">384.81</cell><cell>37.93</cell><cell></cell><cell>379.3</cell><cell>À1.43</cell></row><row><cell>LU</cell><cell cols="2">877.27</cell><cell>85.16</cell><cell></cell><cell>851.6</cell><cell>À2.92</cell></row><row><cell>MG</cell><cell cols="2">786.34</cell><cell>77.57</cell><cell></cell><cell>775.7</cell><cell>À1.35</cell></row><row><cell>SP</cell><cell cols="2">1,219.16</cell><cell>118.56</cell><cell></cell><cell>1,185.6</cell><cell>À2.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 7</head><label>7</label><figDesc>Results of Time Prediction on IA32 Cluster</figDesc><table><row><cell></cell><cell>Original</cell><cell>Dwarf</cell><cell>Dwarf</cell><cell></cell></row><row><cell>NPB</cell><cell>program</cell><cell>code</cell><cell>code</cell><cell>Error</cell></row><row><cell>Application</cell><cell>running</cell><cell>running</cell><cell>prediction</cell><cell>rate (%)</cell></row><row><cell></cell><cell>time(s)</cell><cell>time(s)</cell><cell>time(s)</cell><cell></cell></row><row><cell>BT</cell><cell>3,558.72</cell><cell>337.65</cell><cell>3,376.5</cell><cell>À5.12</cell></row><row><cell>CG</cell><cell>1,042.09</cell><cell>101.72</cell><cell>1,017.2</cell><cell>À2.39</cell></row><row><cell>LU</cell><cell>3,191.50</cell><cell>297.54</cell><cell>2,975.4</cell><cell>À6.77</cell></row><row><cell>MG</cell><cell>2,040.17</cell><cell>183.94</cell><cell>1,839.4</cell><cell>À9.84</cell></row><row><cell>SP</cell><cell>4,295.63</cell><cell>401.81</cell><cell>4,018.1</cell><cell>À6.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 9</head><label>9</label><figDesc>Collective Functions Involved in NPB &amp; Nbody Applications</figDesc><table><row><cell>Collective Func</cell><cell cols="8">BT CG EP FT IS LU MG SP Nbody</cell></row><row><cell>MPI_Bcast MPI_Gather</cell><cell>p</cell><cell></cell><cell></cell><cell>p</cell><cell>p</cell><cell>p</cell><cell>p</cell><cell>p</cell></row><row><cell>MPI_Gatherv MPI_Scatter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>p</cell></row><row><cell>MPI_Scatterv MPI_Allgather</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>p</cell></row><row><cell>MPI_Allgatherv MPI_Alltoall MPI_Alltoallv MPI_Barrier MPI_Reduce MPI_Allreduce MPI_Reduce_scatter</cell><cell>p p p</cell><cell>p p</cell><cell>p p</cell><cell>p p p p p p p</cell><cell>p p</cell><cell>p p p</cell><cell>p p</cell><cell>p p p p</cell></row><row><cell>MPI_Scan</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MPI_Op_create</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MPI_Op_free</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Prof. Marc Snir and Dr. Babak Behzad at the University of Illinois at Urbana-Champaign for insightful discussion about the paper revision. They also thank the anonymous reviewers' comments, which are all valuable and very helpful for revising and improving our paper. </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weizhe Zhang is a professor in the School of Computer Science and Technology, Harbin Institute of Technology, China. He has been a visiting scholar in the Department of Computer Science, University of Illinois at Urbana-Champaign and the University of Houston. His research interests are primarily in parallel computing, distributed computing, cloud computing. He has published more than 100 academic papers in journals, books, and conference proceedings. He is a member of the IEEE.</p><p>Albert M.K. Cheng received the BA degree with highest honors in computer science, graduating Phi Beta Kappa, the MS degree in computer science with a minor in electrical engineering, and the PhD degree in computer science, all from The University of Texas at Austin, where he held a GTE Foundation Doctoral Fellowship. He is a professor and a former interim associate chair of the Computer Science Department, University of Houston. He received numerous awards. He is the author of the popular textbook entitled Real-Time Systems: Scheduling, Analysis, and Verification (Wiley) and more than 200 refereed publications on real-time, embedded, and cyber-physical systems. He is a senior member of the IEEE and a fellow of the Institute of Physics.</p><p>Jaspal Subhlok received the PhD degree in computer science from Rice University. His research interest involves high performance computing. He is a professor and chair of the Computer Science Department, University of Houston. He has published more than 100 academic papers in journals, books, and conference proceedings. He is a member of the IEEE.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Grid: A new infrastructure for 21st century science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grid Computing: Making the Global Infrastructure a Reality</title>
		<meeting><address><addrLine>Hoboken, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="51" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multisite co-allocation scheduling algorithms for parallel jobs in computing grid environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. China Ser. F: Inf. Sci</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="906" to="926" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Path grammar guided trace compression and trace approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th IEEE Int. Symp. High Perform</title>
		<meeting>15th IEEE Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="57" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling TCP latency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cardwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INFOCOM</title>
		<meeting>INFOCOM</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1742" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Performance prediction in a grid environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Escale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Labarta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Uller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grid Computing</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Skeleton based performance prediction on shared networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sodhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Subhlok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Cluster Comput. Grid</title>
		<meeting>IEEE Int. Symp. Cluster Comput. Grid</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="723" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Performance prediction with skeletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sodhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Subhlok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cluster Comput</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="165" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Construction and evaluation of coordinated performance skeletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Subhlok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Int. Joint Conf. High Perform</title>
		<meeting>15th Int. Joint Conf. High Perform</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="73" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient discovery of loop nests in execution traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Subhlok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hammen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Model</title>
		<meeting>IEEE Int. Symp. Model</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extraction of parallel application signatures for performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rexachs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Luque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 12th IEEE Int. Conf. High Perform</title>
		<meeting>12th IEEE Int. Conf. High Perform</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="223" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ScalaTrace: Scalable compression and replay of communication traces for high-performance computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ratn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>De Supinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Parallel Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="696" to="710" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Preserving time in large-scale communication traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ratn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>De Supinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Annu. Int. Conf. Supercomput</title>
		<meeting>22nd Annu. Int. Conf. Supercomput</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="46" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The NAS parallel benchmarks summary and preliminary results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Barszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Browning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dagum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fatoohi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Frederickson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Lasinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Weeratunga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th Annu. Int. Conf. Supercomput</title>
		<meeting>5th Annu. Int. Conf. Supercomput</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="158" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Message Passing Interface Forum</title>
		<ptr target="http://www.mpi-forum.org/" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The vampirtrace plugin counter interface: Introduction and examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sch€ One</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tsch€ Uter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ilsche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hackenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro-Par Parallel Process. Workshops</title>
		<meeting>Euro-Par Parallel ess. Workshops</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="501" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical scalability analysis of communication operations in distributed applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="123" to="132" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gusfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology</title>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Cambridge Univ. Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An optimal algorithm for computing the repetitions in a word</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crochemore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Lett</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="244" to="250" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal off-line detection of repetitions in a string</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Apostolico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Preparata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="315" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An O(nlogn) algorithm for finding all repetitions in a string</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Main</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Lorentz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Algorithms</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="422" to="432" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Suffix arrays: A new method for online string searches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Manber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="935" to="948" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lothaire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Combinatorics on Words</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<date type="published" when="2005" />
			<publisher>Cambridge Univ. Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The LCA problem revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th LATIN Amer. Symp.: Theoretical Informat</title>
		<meeting>4th LATIN Amer. Symp.: Theoretical Informat</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="88" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new succinct representation of RMQinformation and improvements in the enhanced suffix array</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Heun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorics, Algorithms, Probabilistic and Experimental Methodologies</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="459" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Linear work suffix array construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Burkhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="918" to="936" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Undergraduate Petascale Education Program</title>
		<ptr target="http://www.shodor.org/petascale/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>NCSA Blue Waters project</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Algorithmic Skeletons: Structured Management of Parallel Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Cole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Pitman</publisher>
			<pubPlace>London, U.K</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fast: A functional algorithm simulation testbed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Dikaiakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Steiglitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Int. Workshop Model</title>
		<meeting>2nd Int. Workshop Model</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="142" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An evaluation of linear models for host load prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Dinda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>O'hallaron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th Int. Symp. High Perform</title>
		<meeting>8th Int. Symp. High Perform</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Performance prediction based on inherent program similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Phansalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eeckhout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Georges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Bosschere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Int. Conf. Parallel Archit. Compilation Techn</title>
		<meeting>15th Int. Conf. Parallel Archit. Compilation Techn</meeting>
		<imprint>
			<date type="published" when="2006-09" />
			<biblScope unit="page" from="114" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Compact application signatures for parallel and distributed scientific codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/IEEE Conf. Supercomput</title>
		<meeting>ACM/IEEE Conf. Supercomput</meeting>
		<imprint>
			<date type="published" when="2002-11" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatically characterizing large scale program behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hamerly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Calder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGARCH Comput. Archit. News</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="45" to="57" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Performance modeling and system management for multi-component online services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2nd Conf. Symp. Netw. Syst. Des. Implementation</title>
		<meeting>2nd Conf. Symp. Netw. Syst. Des. Implementation</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="71" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An analytical model for multi-tier internet services and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Urgaonkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pacifici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spreitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tantawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS Perform. Eval. Rev</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="291" to="302" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">CloudProphet: Towards application performance prediction in cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="426" to="427" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probabilistic communication and I/O tracing with deterministic replay at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Parallel Process</title>
		<meeting>Int. Conf. Parallel ess</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automatic generation of executable communication specifications from parallel applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Supercomput</title>
		<meeting>Int. Conf. Supercomput</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Phantom: Predicting performance of parallel applications on large-scale parallel machines using a single node</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigplan Notices</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="305" to="314" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Performance prediction for MPI parallel jobs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Cluster Comput. Workshops CLUSTER WORKSHOPS</title>
		<meeting>IEEE Int. Conf. Cluster Comput. Workshops CLUSTER WORKSHOPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="136" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dwarfcode</surname></persName>
		</author>
		<ptr target="https://github.com/wzzhang-HIT/DwarfCode" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">SST: The structural simulation toolkit</title>
		<ptr target="http://sst.sandia.gov/" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Sandia National Laboratories</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bigsim: A parallel simulator for performance prediction of extremely large parallel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gunavardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Laxmikant</surname></persName>
		</author>
		<ptr target="http://charm.cs.uiuc.edu/research/bigsim" />
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Int. Parallel Distributed Process. Symp</title>
		<meeting>18th Int. Parallel Distributed ess. Symp</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">78</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Rensselaer&apos;s Optimistic simulation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ross</surname></persName>
		</author>
		<ptr target="https://github.com/carothersc/ROSS/wiki" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">PSINS: An open source event tracer and execution simulator for MPI applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tikir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laurenzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Euro-Par Parallel Process</title>
		<meeting>Euro-Par Parallel ess</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="135" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Performance modeling of hybrid mpi/ openmp scientific applications on large-scale multicore cluster systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 14th Int. Conf</title>
		<meeting>IEEE 14th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="181" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">MPI-ACC: An integrated and extensible approach to data movement in accelerator-based systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Buntinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bisset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thakur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 14th Int. Conf. High Perform</title>
		<meeting>IEEE 14th Int. Conf. High Perform</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="647" to="654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">MPI alltoall personalized exchange on GPGPU clusters: Design alternatives and benefit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Potluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kandalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Panda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf.Cluster Comput</title>
		<meeting>IEEE Int. Conf.Cluster Comput</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="420" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">MPI runtime error detection with MUST: Advances in deadlock detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hilbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Protze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Supinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>M€</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Programm</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="109" to="121" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J N</forename><surname>Wylie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abrah Am</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The Scalasca performance toolset architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency Comput.: Practice Exp</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="702" to="719" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vmpir-Performance</surname></persName>
		</author>
		<ptr target="https://www.vampir.eu/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
